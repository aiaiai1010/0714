<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Head Pose Estimation</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>
  <style>
    video, canvas { position: absolute; top:0; left:0; width:100%; height:100%; object-fit:cover; }
    #overlay { position: absolute; top:10px; left:10px; color:#0f0; background:rgba(0,0,0,0.5); padding:5px; font-family:monospace; }
  </style>
</head>
<body>
  <video id="input_video" autoplay playsinline></video>
  <canvas id="output_canvas"></canvas>
  <div id="overlay"></div>
  <script>
    const video = document.getElementById('input_video');
    const canvas = document.getElementById('output_canvas');
    const ctx = canvas.getContext('2d');
    const overlay = document.getElementById('overlay');

    let cvReady = false;
    cv['onRuntimeInitialized']=()=>{ cvReady = true; };

    const faceMesh = new FaceMesh({ locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}` });
    faceMesh.setOptions({ selfieMode:true, maxNumFaces:1, refineLandmarks:true, minDetectionConfidence:0.5, minTrackingConfidence:0.5 });
    faceMesh.onResults(onResults);
    new Camera(video, { onFrame: async()=>{ if(cvReady) await faceMesh.send({image: video}); }, width:640, height:480 }).start();

    const modelPoints = cv.matFromArray(6,3,cv.CV_64FC1,[
       0.0, 0.0, 0.0,
       0.0, -63.6, -12.5,
       -43.3, 32.7, -26.0,
       43.3, 32.7, -26.0,
       -28.9, -28.9, -24.1,
       28.9, -28.9, -24.1
    ]);

    function onResults(results){
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.clearRect(0,0,canvas.width,canvas.height);
      ctx.drawImage(results.image,0,0,canvas.width,canvas.height);
      overlay.textContent = '';

      if(results.multiFaceLandmarks){
        const lm = results.multiFaceLandmarks[0];
        drawConnectors(ctx, lm, FACEMESH_TESSELATION, {color:'#C0C0C070', lineWidth:1});
        drawConnectors(ctx, lm, FACEMESH_FACE_OVAL, {color:'#E0E0E0'});
        
        const imagePoints = cv.matFromArray(6,2,cv.CV_64FC1, [
          lm[1].x*canvas.width, lm[1].y*canvas.height,
          lm[152].x*canvas.width, lm[152].y*canvas.height,
          lm[263].x*canvas.width, lm[263].y*canvas.height,
          lm[33].x*canvas.width, lm[33].y*canvas.height,
          lm[61].x*canvas.width, lm[61].y*canvas.height,
          lm[291].x*canvas.width, lm[291].y*canvas.height
        ]);

        const focal = canvas.width;
        const center = [canvas.width/2, canvas.height/2];
        const cameraMatrix = cv.matFromArray(3,3,cv.CV_64FC1, [
          focal,0,center[0],
          0,focal,center[1],
          0,0,1
        ]);
        const distCoeffs = cv.Mat.zeros(4,1,cv.CV_64FC1);

        const rvec = new cv.Mat();
        const tvec = new cv.Mat();
        cv.solvePnP(modelPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec);

        const R = new cv.Mat();
        cv.Rodrigues(rvec, R);
        const angles = cv.RQDecomp3x3(R);
        overlay.textContent = `Yaw:${angles[1][1].toFixed(1)}° Pitch:${angles[1][0].toFixed(1)}° Roll:${angles[1][2].toFixed(1)}°`;

        modelPoints.delete(); imagePoints.delete(); cameraMatrix.delete();
        distCoeffs.delete(); rvec.delete(); tvec.delete(); R.delete();
      }
    }
  </script>
</body>
</html>